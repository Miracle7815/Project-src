{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Project src\\\\zero-to-hero\\\\nanogpt\\\\input.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = os.path.join(os.getcwd() , 'input.txt')\n",
    "# print(input_file_path)\n",
    "# if not os.path.exists(input_file_path):\n",
    "#     data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "#     with open(input_file_path, 'w', encoding='utf-8') as f:\n",
    "#         f.write(requests.get(data_url).text)\n",
    "\n",
    "input_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.txt' , 'r' , encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd', '!']\n",
      "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42, 2]\n",
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "stoi = {s : i for i , s in enumerate(chars)}\n",
    "itos = {i : s for s , i in stoi.items()}\n",
    "\n",
    "#take a string , output a list of integers\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "#take a list of integers , output a string\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "# print(stoi)\n",
    "# print(itos)\n",
    "l = encode(\"hello world!\")\n",
    "print([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"hello world!\"))\n",
    "print(decode(encode(\"hello world!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n",
      "[31373, 995, 0]\n",
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "#openai提供的编码器\n",
    "enc_gpt2 = tiktoken.get_encoding(\"gpt2\")\n",
    "print(enc_gpt2.n_vocab)\n",
    "encoding_words = enc_gpt2.encode(\"hello world!\")\n",
    "print(encoding_words)\n",
    "print(enc_gpt2.decode(encoding_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text) , dtype=torch.long)\n",
    "print(data.shape , data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854 111540\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(len(train_data) , len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) , the target is 47\n",
      "When input is tensor([18, 47]) , the target is 56\n",
      "When input is tensor([18, 47, 56]) , the target is 57\n",
      "When input is tensor([18, 47, 56, 57]) , the target is 58\n",
      "When input is tensor([18, 47, 56, 57, 58]) , the target is 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) , the target is 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) , the target is 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) , the target is 58\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1 : block_size + 1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'When input is {context} , the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "target: \n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "------------------------------------------------\n",
      "When input is tensor([24]) , the target is 43\n",
      "When input is tensor([24, 43]) , the target is 58\n",
      "When input is tensor([24, 43, 58]) , the target is 5\n",
      "When input is tensor([24, 43, 58,  5]) , the target is 57\n",
      "When input is tensor([24, 43, 58,  5, 57]) , the target is 1\n",
      "When input is tensor([24, 43, 58,  5, 57,  1]) , the target is 46\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46]) , the target is 43\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) , the target is 39\n",
      "When input is tensor([44]) , the target is 53\n",
      "When input is tensor([44, 53]) , the target is 56\n",
      "When input is tensor([44, 53, 56]) , the target is 1\n",
      "When input is tensor([44, 53, 56,  1]) , the target is 58\n",
      "When input is tensor([44, 53, 56,  1, 58]) , the target is 46\n",
      "When input is tensor([44, 53, 56,  1, 58, 46]) , the target is 39\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39]) , the target is 58\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) , the target is 1\n",
      "When input is tensor([52]) , the target is 58\n",
      "When input is tensor([52, 58]) , the target is 1\n",
      "When input is tensor([52, 58,  1]) , the target is 58\n",
      "When input is tensor([52, 58,  1, 58]) , the target is 46\n",
      "When input is tensor([52, 58,  1, 58, 46]) , the target is 39\n",
      "When input is tensor([52, 58,  1, 58, 46, 39]) , the target is 58\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58]) , the target is 1\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) , the target is 46\n",
      "When input is tensor([25]) , the target is 17\n",
      "When input is tensor([25, 17]) , the target is 27\n",
      "When input is tensor([25, 17, 27]) , the target is 10\n",
      "When input is tensor([25, 17, 27, 10]) , the target is 0\n",
      "When input is tensor([25, 17, 27, 10,  0]) , the target is 21\n",
      "When input is tensor([25, 17, 27, 10,  0, 21]) , the target is 1\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1]) , the target is 54\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) , the target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0 , len(data) - block_size , (batch_size,))\n",
    "    #torch.stack: cat the input sequence\n",
    "    x = torch.stack([data[i: i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + 1 + block_size] for i in ix])\n",
    "    return x , y\n",
    "\n",
    "xb , yb = get_batch('train')\n",
    "print(f\"input: \" )\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"target: \")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b , :t+1]   \n",
    "        target = yb[b , t]\n",
    "        print(f'When input is {context} , the target is {target}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(5.0364, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self , vocab_size):\n",
    "        super().__init__()\n",
    "        #Embedding将词汇表中的词汇映射到多维向量中，矩阵行数表示词汇表大小，矩阵列数表示每个token的向量维度\n",
    "        #用embedding层作为二元语言模型的表，生成的词只依赖于前一个词\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size , vocab_size)\n",
    "\n",
    "    def forward(self , idx , targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T , C)\n",
    "            targets = targets.view(B*T)\n",
    "            #cross_entropy要求logtis为(sample_num , classes_num) targets(class of every sample,)\n",
    "            # print(logits.shape , targets.shape) logtits.shape = \n",
    "            # (batch_size * block_size , vocab_size)\n",
    "\n",
    "            loss = F.cross_entropy(logits , targets)\n",
    "\n",
    "        return logits , loss\n",
    "    \n",
    "    def generate(self , idx , max_new_token):\n",
    "        for _ in range(max_new_token):\n",
    "            logits , loss = self(idx)\n",
    "            logits = logits[: , -1 , :]          #提取时间维度上的最后一个位置\n",
    "            probs = F.softmax(logits , dim=-1)\n",
    "            idx_next = torch.multinomial(probs , num_samples=1)\n",
    "            idx = torch.cat((idx , idx_next) , dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits , loss = m(xb , yb)       #输入4*8 输出 4 * 8 * 56\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 101])\n",
      "\n",
      "k'.?nA!LgjgL&jcM-sZW!HFsWt'rv.x;z&hPyd'XHOxnAcj.erRjcLxxVFSrOpW.oeGJ Ai$yi&!mRfeopx,f.e..iBgxVrl-VTh\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1 , 1) , dtype=torch.long)\n",
    "print(m.generate(idx , max_new_token=100).shape)  \n",
    "print(decode(m.generate(idx , max_new_token=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.574044942855835\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters() , lr=1e-3)\n",
    "\n",
    "batch_size = 32\n",
    "for step in range(10000):\n",
    "    xb , yb = get_batch('train')\n",
    "\n",
    "    logits , loss = m(xb , yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "ARERI ISOLBUS:\n",
      "QUK: ast, plt t wadyotl\n",
      "I bel qunganonoth he m he de avellis k'l, tond soran:\n",
      "\n",
      "WI he toust are bott oe n t s d je hid t his IAces I my ig t\n",
      "Ril'swoll e pupat inould candenothiqu heamer te\n",
      "Wht s\n",
      "\n",
      "MI wect!-lltherotheve t fe;\n",
      "WAnd py;\n",
      "\n",
      "PO t s ld tathat, ir V\n",
      "IO thesecin teot tit ado ilorer.\n",
      "Ply, d'stacoes, ld omat mealellly yererer EMEvesas ie IZEd pave mautoofareanerllleyomerer but?\n",
      "The t,\n",
      "Ith'dwitile w? beren to'd ff a atrts brey s\n",
      "\n",
      "ESesenther:\n",
      "Ithon f at par,\n",
      "NRmamy an flictong \n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx , max_new_token=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n",
      "torch.Size([4, 8, 2]) tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n",
      "torch.Size([4, 8, 2]) tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "#我们希望第i个位置生成的内容，只能看见前i-1个位置的内容而不是全部内容\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4 , 8 , 2\n",
    "x = torch.randn(B, T , C)\n",
    "print(x.shape)\n",
    "\n",
    "#实现1：\n",
    "x_bow = torch.zeros((B , T , C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b , :t+1]\n",
    "        x_bow[b , t] = torch.mean(xprev , 0)\n",
    "\n",
    "print(x.shape , x[0])\n",
    "print(x_bow.shape , x_bow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实现2\n",
    "torch.manual_seed(42)\n",
    "# a = torch.ones(3 , 3)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a , 1 ,keepdim=True)\n",
    "print(a)\n",
    "b = torch.randint(0 , 10 , (3 , 2)).float()\n",
    "c = a @ b\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(torch.tril(torch.ones(3 , 3))) #生成下三角\n",
    "\n",
    "wei = torch.tril(torch.ones(T , T))\n",
    "wei = wei / wei.sum(1 , keepdim=True)\n",
    "x_bow2 = wei @ x      #(T * T) @ (B , T , C)  ---> (B , T , T) @ (B , T , C)\n",
    "torch.allclose(x_bow , x_bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Softmax\n",
    "wei = torch.zeros((T , T))\n",
    "tril = torch.tril(torch.ones(T , T))\n",
    "wei = wei.masked_fill(tril == 0 , float('-inf'))    #填充\n",
    "print(wei)\n",
    "wei = F.softmax(wei , dim=-1)\n",
    "print(wei)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(x_bow , xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
      "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
      "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
      "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
      "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
      "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
      "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
      "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
      "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## self attention\n",
    "torch.manual_seed(1337)\n",
    "B , T , C = 4 , 8 , 32\n",
    "x = torch.randn(B , T , C)\n",
    "\n",
    "#single head self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C , head_size , bias=False)\n",
    "query = nn.Linear(C , head_size , bias=False)\n",
    "value = nn.Linear(C , head_size , bias=False)\n",
    "k = key(x)             # B * T * head_size\n",
    "q = query(x)           # B * T * head_size\n",
    "\n",
    "wei = q @ k.transpose(-2 , -1)   #B * T * head_size @ B * head_size * T ---> B * T * T\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T , T))\n",
    "# wei = torch.zeros((T , T))\n",
    "#对于语言模型，需要采用掩码attention，模型只能从过去的序列中获取信息\n",
    "wei = wei.masked_fill(tril == 0 , float('-inf'))\n",
    "wei = F.softmax(wei , dim=-1)\n",
    "print(wei)\n",
    "# out = wei @ x\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., -inf, -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., -inf],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(8 , 8))\n",
    "wei = torch.ones((4 , 8 , 8))\n",
    "print(wei.masked_fill(tril[:8 , : 8] == 0 , float('-inf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Layer Normalization\n",
    "class LayerNorm1d:\n",
    "    def __init__(self , dim , eps=1e-5 , momentum = 0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self , x):\n",
    "        xmean = x.mean(1 , keepdim = True)\n",
    "        xvar = x.var(1 , keepdim=True)\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "\n",
    "        return self.out \n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma , self.beta]\n",
    "    \n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32 , 100)\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[: , 0].mean() , x[: , 0].std()        #batchNorm 则为0，1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0 , :].mean() , x[0 , :].std()           #layerNorm为0 ，1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25105,\n",
       " 29233,\n",
       " 20320,\n",
       " 20013,\n",
       " 22269,\n",
       " 44,\n",
       " 73,\n",
       " 32,\n",
       " 108,\n",
       " 111,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 67,\n",
       " 104,\n",
       " 105,\n",
       " 110,\n",
       " 97,\n",
       " 33,\n",
       " 33,\n",
       " 33]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unicode编码\n",
    "\n",
    "[ord(x) for x in \"我爱你中国,I love China!!!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[230,\n",
       " 136,\n",
       " 145,\n",
       " 231,\n",
       " 136,\n",
       " 177,\n",
       " 228,\n",
       " 189,\n",
       " 160,\n",
       " 228,\n",
       " 184,\n",
       " 173,\n",
       " 229,\n",
       " 155,\n",
       " 189,\n",
       " 44,\n",
       " 73,\n",
       " 32,\n",
       " 108,\n",
       " 111,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 67,\n",
       " 104,\n",
       " 105,\n",
       " 110,\n",
       " 97,\n",
       " 33,\n",
       " 33,\n",
       " 33]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"我爱你中国,I love China!!!\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Ｕｎｉｃｏｄｅ! 🅤🅝🅘🅒🅞🅓🅔‽ 🇺‌🇳‌🇮‌🇨‌🇴‌🇩‌🇪! 😄 \n",
      "length:  35\n",
      "-----------------\n",
      "[239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 240, 159, 133, 164, 240, 159, 133, 157, 240, 159, 133, 152, 240, 159, 133, 146, 240, 159, 133, 158, 240, 159, 133, 147, 240, 159, 133, 148, 226, 128, 189, 32, 240, 159, 135, 186, 226, 128, 140, 240, 159, 135, 179, 226, 128, 140, 240, 159, 135, 174, 226, 128, 140, 240, 159, 135, 168, 226, 128, 140, 240, 159, 135, 180, 226, 128, 140, 240, 159, 135, 169, 226, 128, 140, 240, 159, 135, 170, 33, 32, 240, 159, 152, 132, 32]\n",
      "length:  108\n"
     ]
    }
   ],
   "source": [
    "text = \"Ｕｎｉｃｏｄｅ! 🅤🅝🅘🅒🅞🅓🅔‽ 🇺‌🇳‌🇮‌🇨‌🇴‌🇩‌🇪! 😄 \"\n",
    "tokens = text.encode(\"utf-8\")\n",
    "tokens = list(map(int , tokens))\n",
    "print(\"-----------------\")\n",
    "print(text)\n",
    "print(\"length: \" , len(text))\n",
    "print(\"-----------------\")\n",
    "print(tokens)\n",
    "print(\"length: \" , len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, (240, 159)), (7, (226, 128)), (7, (159, 135)), (7, (159, 133)), (6, (239, 189)), (6, (140, 240)), (6, (128, 140)), (3, (32, 240)), (2, (33, 32)), (1, (239, 188)), (1, (189, 143)), (1, (189, 142)), (1, (189, 137)), (1, (189, 133)), (1, (189, 132)), (1, (189, 131)), (1, (189, 32)), (1, (188, 181)), (1, (186, 226)), (1, (181, 239)), (1, (180, 226)), (1, (179, 226)), (1, (174, 226)), (1, (170, 33)), (1, (169, 226)), (1, (168, 226)), (1, (164, 240)), (1, (159, 152)), (1, (158, 240)), (1, (157, 240)), (1, (152, 240)), (1, (152, 132)), (1, (148, 226)), (1, (147, 240)), (1, (146, 240)), (1, (143, 239)), (1, (142, 239)), (1, (137, 239)), (1, (135, 186)), (1, (135, 180)), (1, (135, 179)), (1, (135, 174)), (1, (135, 170)), (1, (135, 169)), (1, (135, 168)), (1, (133, 164)), (1, (133, 158)), (1, (133, 157)), (1, (133, 152)), (1, (133, 148)), (1, (133, 147)), (1, (133, 146)), (1, (133, 33)), (1, (132, 239)), (1, (132, 32)), (1, (131, 239)), (1, (128, 189))]\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids , ids[1:]):\n",
    "        counts[pair] = counts.get(pair , 0) + 1\n",
    "    return counts \n",
    "\n",
    "stats = get_stats(tokens)\n",
    "# print(sorted(((v , k) for k , v in stats.items()) , reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 256, 133, 164, 256, 133, 157, 256, 133, 152, 256, 133, 146, 256, 133, 158, 256, 133, 147, 256, 133, 148, 226, 128, 189, 32, 256, 135, 186, 226, 128, 140, 256, 135, 179, 226, 128, 140, 256, 135, 174, 226, 128, 140, 256, 135, 168, 226, 128, 140, 256, 135, 180, 226, 128, 140, 256, 135, 169, 226, 128, 140, 256, 135, 170, 33, 32, 256, 152, 132, 32]\n",
      "length: 93\n"
     ]
    }
   ],
   "source": [
    "top_pair = max(stats , key=stats.get)\n",
    "top_pair\n",
    "\n",
    "#将ids替换为idx\n",
    "def merge(ids , pair , idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids\n",
    "\n",
    "# print(merge([5 , 6 , 6 , 7 , 9 , 1] , (6 , 7) , 99))\n",
    "tokens2 = merge(tokens , top_pair , 256)\n",
    "print(tokens2)\n",
    "print(f'length: {len(tokens2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (240, 159) into a new token 256\n",
      "merging (256, 133) into a new token 257\n",
      "merging (226, 128) into a new token 258\n",
      "merging (256, 135) into a new token 259\n",
      "merging (239, 189) into a new token 260\n",
      "merging (258, 140) into a new token 261\n",
      "merging (261, 259) into a new token 262\n",
      "merging (33, 32) into a new token 263\n",
      "merging (239, 188) into a new token 264\n",
      "merging (264, 181) into a new token 265\n",
      "merging (265, 260) into a new token 266\n",
      "merging (266, 142) into a new token 267\n",
      "merging (267, 260) into a new token 268\n",
      "merging (268, 137) into a new token 269\n",
      "merging (269, 260) into a new token 270\n",
      "merging (270, 131) into a new token 271\n",
      "merging (271, 260) into a new token 272\n",
      "merging (272, 143) into a new token 273\n",
      "merging (273, 260) into a new token 274\n",
      "merging (274, 132) into a new token 275\n",
      "merging (275, 260) into a new token 276\n",
      "[276, 133, 263, 257, 164, 257, 157, 257, 152, 257, 146, 257, 158, 257, 147, 257, 148, 258, 189, 32, 259, 186, 262, 179, 262, 174, 262, 168, 262, 180, 262, 169, 262, 170, 263, 256, 152, 132, 32]\n",
      "tokens length:  108\n",
      "ids length:  39\n",
      "compression ratio: 2.77X\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 276\n",
    "num_merges = vocab_size - 255\n",
    "ids = list(tokens)\n",
    "\n",
    "merges = {}\n",
    "for i in range(num_merges):\n",
    "    stats = get_stats(ids)\n",
    "    pair = max(stats , key = stats.get)\n",
    "    idx = 256 + i\n",
    "    ids = merge(ids , pair , idx)\n",
    "    print(f'merging {pair} into a new token {idx}')\n",
    "    merges[pair] = idx\n",
    "\n",
    "print(\"tokens length: \" , len(tokens))\n",
    "print(\"ids length: \" , len(ids))\n",
    "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\n"
     ]
    }
   ],
   "source": [
    "vocab = {idx:bytes([idx]) for idx in range(256)}\n",
    "for (p0 , p1) , idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode(ids):\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode(\"utf-8\" , errors=\"replace\")      #默认为'strict'，此时在某些不符合格式要求的会报错\n",
    "    return text\n",
    "\n",
    "print(decode([128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(240, 159): 256,\n",
       " (256, 133): 257,\n",
       " (226, 128): 258,\n",
       " (256, 135): 259,\n",
       " (239, 189): 260,\n",
       " (258, 140): 261,\n",
       " (261, 259): 262,\n",
       " (33, 32): 263,\n",
       " (239, 188): 264,\n",
       " (264, 181): 265,\n",
       " (265, 260): 266,\n",
       " (266, 142): 267,\n",
       " (267, 260): 268,\n",
       " (268, 137): 269,\n",
       " (269, 260): 270,\n",
       " (270, 131): 271,\n",
       " (271, 260): 272,\n",
       " (272, 143): 273,\n",
       " (273, 260): 274,\n",
       " (274, 132): 275,\n",
       " (275, 260): 276}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104]\n"
     ]
    }
   ],
   "source": [
    "def encode(text):\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    while len(tokens) >= 2:\n",
    "        stats = get_stats(tokens)\n",
    "        #token值越小的代表出现次数越多，最先被合并\n",
    "        pair = min(stats , key = lambda p: merges.get(p , float(\"inf\")))\n",
    "        if pair not in merges:\n",
    "            break\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens , pair , idx)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "print(encode(\"h\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', '    ', ' world', \"'s\", ' my', ' dog', ' 123', ' !!!']\n"
     ]
    }
   ],
   "source": [
    "gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
    "print(re.findall(gpt2pat , \"hello     world's my dog 123 !!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'for', ' i', ' in', ' range', '(', '1', ' ,', ' 101', '):', '\\n   ', ' if', ' i', ' %', ' 3', ' ==', ' 0', ' and', ' i', ' %', ' 5', ' ==', ' 0', ':', '\\n       ', ' print', '(\"', 'FizzBuzz', '\")', '\\n   ', ' elif', ' i', ' %', ' 3', ' ==', ' 0', ':', '\\n       ', ' print', '(\"', 'Fizz', '\")', '\\n   ', ' elif', ' i', ' %', ' 5', ' ==', ' 0', ':', '\\n       ', ' print', '(\"', 'Buzz', '\")', '\\n   ', ' else', ':', '\\n       ', ' print', '(', 'i', ')', '\\n']\n"
     ]
    }
   ],
   "source": [
    "example = \"\"\"\n",
    "for i in range(1 , 101):\n",
    "    if i % 3 == 0 and i % 5 == 0:\n",
    "        print(\"FizzBuzz\")\n",
    "    elif i % 3 == 0:\n",
    "        print(\"Fizz\")\n",
    "    elif i % 5 == 0:\n",
    "        print(\"Buzz\")\n",
    "    else:\n",
    "        print(i)\n",
    "\"\"\"\n",
    "\n",
    "print(re.findall(gpt2pat , example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special tokens          <endoftext>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPENAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
